{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, cv2, math\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_retinanet.utils.compute_overlap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e738eb867403>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_path_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'snap_nodule_dector_wts.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# load retinanet model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resnet50'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlabels_to_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'N'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ccarley\\Desktop\\snap\\nodule_detection\\keras_retinanet\\models\\__init__.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, backbone_name)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \"\"\"\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ccarley\\Desktop\\snap\\nodule_detection\\keras_retinanet\\models\\__init__.py\u001b[0m in \u001b[0;36mbackbone\u001b[1;34m(backbone_name)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'resnet'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResNetBackbone\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;34m'mobilenet'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackbone_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmobilenet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMobileNetBackbone\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ccarley\\Desktop\\snap\\nodule_detection\\keras_retinanet\\models\\resnet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_resnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mretinanet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBackbone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ccarley\\Desktop\\snap\\nodule_detection\\keras_retinanet\\models\\retinanet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAnchorParameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0massert_training_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ccarley\\Desktop\\snap\\nodule_detection\\keras_retinanet\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_misc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRegressBoxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUpsampleLike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAnchors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClipBoxes\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfilter_detections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFilterDetections\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ccarley\\Desktop\\snap\\nodule_detection\\keras_retinanet\\layers\\_misc.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0manchors\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutils_anchors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ccarley\\Desktop\\snap\\nodule_detection\\keras_retinanet\\utils\\anchors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_overlap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_overlap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_retinanet.utils.compute_overlap'"
     ]
    }
   ],
   "source": [
    "model_path_name='snap_nodule_dector_wts.h5'\n",
    "# load retinanet model\n",
    "model = models.load_model(model_path_name, backbone_name='resnet50')\n",
    "model = models.convert_model(model)\n",
    "labels_to_names = {0.0: 'N'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image location\n",
    "data_location = '../sample_images'\n",
    "imagefile=os.listdir(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output location : images with predicted nodules\n",
    "directory='../sample_outputs/nodules'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retinanet_input = 512\n",
    "patchsize = 256\n",
    "class_th = 0.5\n",
    "import pandas as pd\n",
    "for file in imagefile:\n",
    "    image_path =data_location +'/' + file\n",
    "    imagename=file.split('/')[-1]\n",
    "    imagefull = read_image_bgr(image_path)\n",
    "    h=math.ceil(imagefull.shape[0]/patchsize)*patchsize-imagefull.shape[0]\n",
    "    w=math.ceil(imagefull.shape[1]/patchsize)*patchsize-imagefull.shape[1]\n",
    "    imagefull= cv2.copyMakeBorder(imagefull,0,h,0,w,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "    I=np.zeros(imagefull.shape)\n",
    "    \n",
    "    number_nodules=0\n",
    "    dicts = {'xc':[], 'yc':[],'area':[],'box_label':[]}\n",
    "    \n",
    "    # make and loop over the patches\n",
    "    for row in range(patchsize,imagefull.shape[0]+1,patchsize):\n",
    "        for col in range(patchsize,imagefull.shape[1]+1,patchsize):\n",
    "            image=imagefull[row-patchsize:row,col-patchsize:col,:]\n",
    "            draw = image.copy()\n",
    "            \n",
    "            # preprocess image for network\n",
    "            image = preprocess_image(image)\n",
    "            image, scale = resize_image(image,retinanet_input)\n",
    "            draw, scale2 = resize_image(draw,patchsize)\n",
    "            \n",
    "            # process image\n",
    "            boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "            \n",
    "            # correct for image scale\n",
    "            boxes /= scale\n",
    "                        \n",
    "            for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "                x1=box[0]+col-patchsize\n",
    "                y1=box[1]+row-patchsize\n",
    "                x2=box[2]+col-patchsize\n",
    "                y2=box[3]+row-patchsize\n",
    "                if score < class_th:\n",
    "                    break\n",
    "                number_nodules=number_nodules+1\n",
    "                \n",
    "                dicts['xc'].append((x1+x2)/2)\n",
    "                dicts['yc'].append((y1+y2)/2)\n",
    "                dicts['area'].append((box[2] - box[0] + 1) * (box[3] - box[1] + 1))\n",
    "                dicts['box_label'].append(box)\n",
    "    \n",
    "                color = label_color(label)\n",
    "                b = box.astype(int)\n",
    "                draw_box(draw, b, color=color)\n",
    "                \n",
    "                caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "                draw_caption(draw, b, caption)\n",
    "            I[row-patchsize:row,col-patchsize:col,:]=draw\n",
    "    \n",
    "    cv2.imwrite(directory+'/'+imagename,I)\n",
    "    print('number of nodules',number_nodules)\n",
    "    df=pd.DataFrame.from_dict(dicts)\n",
    "    df.to_csv(directory+'/'+imagename[:-4]+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
